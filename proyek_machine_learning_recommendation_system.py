# -*- coding: utf-8 -*-
"""Proyek Machine Learning_Recommendation System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12qbH9Y8KOvy-ZHqm3yPz0G5SbeFVFbGv

# Proyek Machine Learning : Recommendation System

Judul : Sistem Rekomendasi Destinasi Wisata Kota Semarang Berbasis Collaborative Filtering

Topik : Rekomendasi Wisata

Tujuan : Membuat sistem rekomendasi berbasis collaborative filtering untuk menampilkan top-n recommendation destinasi wisata di Kota Semarang berdasarkan data user, rating, dan place

Dataset yang digunakan : https://www.kaggle.com/datasets/aprabowo/indonesia-tourism-destination/data?select=tourism_rating.csv

# Melakukan Import terhadap Library yang diperlukan
"""

# Commented out IPython magic to ensure Python compatibility.
# Data Processing
import pandas as pd
import numpy as np
from zipfile import ZipFile
from pathlib import Path

# Data Visualization
import seaborn as sns
import matplotlib.pyplot as plt

# %matplotlib inline
sns.set_palette('Set1')
sns.set()

# Data Modelling
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Avoiding warning while plotting on seaborn
import warnings
warnings.filterwarnings('ignore')

# Uploading file
import os

"""# DATA UNDERSTANDING

1. tourism_with_id.csv - mengandung informasi tempak wisata di 5 kota besar di Indonesia (hanya kota Bandung yang dipakai)

2. user.csv - mengandung informasi pengguna untuk membuat rekomendasi fitur berdasar pengguna

3. tourism_rating.csv - mengandung informasi pengguna, tempat wisata, dan rating untuk membuat sistem rekomendasi berdasar rating

# Menyiapkan Data yang akan digunakan

Menampilkan masing-masing dataset yaitu tourism_with_id.csv dan tourism_rating.csv menggunakan library pandas dari format .csv menjadi dataframe.
"""

# Menyimpan masing-masing dataset kedalam variabel

rating = pd.read_csv('/content/tourism_rating.csv')
place = pd.read_csv('/content/tourism_with_id.csv')
user = pd.read_csv('/content/user.csv')

print('Jumlah place: ', len(place.Place_Id.unique()))
print('Jumlah rating: ', len(rating.Place_Ratings))

"""# Data Features Exploration

# Eksplorasi Fitur-fitur pada Data Place
"""

# Melihat gambaran data place
place.head(2)

#Melihat informasi data place
place.info()

"""File ini terdiri dari 10 kolom sebagai berikut:

* Place_Id: kolom yang menunjukkan id dari setiap tempat wisata.
* Place_Name: kolom yang menunjukkan nama dari setiap tempat wisata.
* Description: kolom yang menunjukkan deskripsi dari setiap tempat wisata.
* Category: kolom yang menunjukkan kategori dari setiap tempat wisata.
* City: kolom yang menunjukkan kota dimana tempat wisata tersebut berada.
* Price: kolom yang menunjukkan harga tiket masuk ke tempat wisata tersebut.
* Rating: kolom yang menunjukkan rating dari setiap tempat wisata.
* Time_Minutes: kolom yang menunjukkan waktu yang diperlukan untuk mengunjungi tempat wisata tersebut.
* Coordinate: kolom yang menunjukkan koordinat dari setiap tempat wisata.
* Lat: kolom yang menunjukkan latitude dari setiap tempat wisata.
* Long: kolom yang menunjukkan longitude dari setiap tempat wisata.
"""

# Membuang kolom yang tidak dipakai
place = place.drop(['Unnamed: 11','Unnamed: 12'],axis=1)
place.head(2)

# Merubah data agar hanya dari Kota Semarang

place = place[place['City']=='Semarang']
place.head(2)

# menghitung rata-rata (mean) dari kolom Time_Minutes pada sebuah DataFrame bernama place.
place.loc[:, ['Time_Minutes']].mean(axis = 0)

#Menampilkan sample dataset place
place.head(5)

#Melakukan pengecekan deskripsi statistik dataset places dengan fitur describe().
place.describe()

"""Berdasarkan output diatas, didapatkan deskripsi statistik yaitu:

* count: Jumlah sampel data
* mean: Nilai rata-rata
* std: Standar deviasi
* min: Nilai minimum
* 25%: Kuartil bawah/Q1
* 50%: Kuartil tengah/Q2/median
* 75%: Kuartil atas/Q3
* max: Nilai maksimum

# Eksplorasi Fitur-fitur pada Data Rating
"""

# melihat gambaran data rating

rating.head()

rating.info()

"""
File ini terdiri dari 3 kolom sebagai berikut:

* User_Id: identitas unik dari setiap pengguna.
* Place_Id: identitas unik dari setiap tempat wisata.
* Place_Ratings: penilaian atau rating yang diberikan oleh pengguna terhadap tempat wisata tertentu."""

# Merubah data rating agar hanya berisi rating pada tempat wisata dari Kota Semarang
rating = pd.merge(rating, place[['Place_Id']], how='right', on='Place_Id')
rating.head()

# Melihat ukuran dataset rating untuk Kota Semarang

rating.shape

#Melakukan pengecekan deskripsi statistik dataset rating dengan fitur describe().
rating.describe()

"""# Eksplorasi Fitur-fitur pada Data User"""

# Melihat gambaran data user

user.head()

# Merubah data user agar hanya berisi user yang pernah megunjungi wisata di Kota Bandung

user = pd.merge(user, rating[['User_Id']], how='right', on='User_Id').drop_duplicates().sort_values('User_Id')
user.head()

# Melihat dataset user yang pernah memberi rating pada wisata di Kota Bandung

user.shape

"""# Exploratory Data Analysis (EDA)

* Tahap eksplorasi penting untuk memahami variabel-variabel pada data serta korelasi antar variabel. Pemahaman terhadap variabel pada data dan korelasinya akan membantu kita dalam menentukan pendekatan atau algoritma yang cocok untuk data kita. Idealnya, kita melakukan eksplorasi data terhadap seluruh variabel.

* Exploratory Data Analysis (EDA) memiliki peranan penting untuk dapat memahami dataset secara baik dan detail.

# Menampilkan informasi terkait tempat yang paling sering dirating
"""

# Menghitung tempat yang paling sering dirating dan mereset indeks
top_10 = rating['Place_Id'].value_counts().reset_index(name='count').head(10)

# Mengganti nama kolom 'index' menjadi 'Place_Id' agar lebih jelas
top_10.rename(columns={'index': 'Place_Id'}, inplace=True)

# Merge dengan DataFrame place untuk mendapatkan nama tempat
top_10 = pd.merge(top_10, place[['Place_Id', 'Place_Name']], how='left', on='Place_Id')

# Menampilkan hasil
print(top_10)

"""# Menampilkan visualisasi data distribusi rating"""

# Membuat visualisasi wisata dengan jumlah rating terbanyak
plt.figure(figsize=(10, 6))
sns.barplot(y='Place_Name', x='count', data=top_10, palette='pastel')
plt.title('Jumlah Tempat Wisata dengan Rating Terbanyak', pad=20)
plt.xlabel('Jumlah Rating')
plt.ylabel('Nama Lokasi')
plt.tight_layout()
plt.show()

"""# Menampilkan visualisasi perbandingan jumlah kategori wisata di Kota Semarang"""

# Membuat visualisasi jumlah kategori wisata di Kota Semarang

sns.countplot(y='Category', data=place, palette='pastel')
plt.title('Perbandingan Jumlah Kategori Wisata di Kota Semarang', pad=20)
plt.show()

"""# Menampilkan visualisasi distribusi usia pengunjung (user)"""

# Membuat visualisasi distribusi usia user

plt.figure(figsize=(5,3))
sns.boxplot(user['Age']);
plt.title('Distribusi Usia User', pad=20)
plt.show()

# Membuat visualisasi distribusi harga masuk tempat wisata

plt.figure(figsize=(12,6))
sns.boxplot(place['Price'])
plt.title('Distribusi Harga Masuk Wisata di Kota Semarang', pad=20)
plt.show()

# menggabungkan Harga dan Waktu_Menit untuk tujuan Kategori
place.groupby("Category").agg({"Price":["mean", "sum"],
                       "Time_Minutes":["mean", "sum"]})

# Memfilter asal kota dari user
askot = user['Location'].apply(lambda x: x.split(',')[0] if isinstance(x, str) else 'Unknown')

# Visualisasi asal kota dari user
plt.figure(figsize=(8,6))
sns.countplot(y=askot, order=askot.value_counts().index, palette='Set2')
plt.title('Jumlah Asal Kota dari User')
plt.show()

most_rated_users = user['User_Id'].value_counts()
most_rated_users

most_rated_rating = rating['Place_Id'].value_counts()
most_rated_rating

"""Setelah melakukan Exploratory Data Analysis (EDA), kita memperoleh hasil:

* Semua (33) tempat yang paling sering dirating
* Semua (297) pengguna telah memberi peringkat minimal 1 kali

Untuk merekomendasikan tempat wisata dengan preferensi teratas, kita dapat meminta setiap pengguna memberi peringkat terhadap semua tempat wisata. Namun tentunya hal tersebut sedikit sulit dicapai. Solusinya kita akan mencoba memprediksi peringkat yang akan diberikan pengguna terhadap tempat wisata.

# DATA PREPARATION

Tahap data preparation merupakan proses transformasi data menjadi bentuk yang dapat diterima oleh model machine learning nanti. Proses data preparation yang dilakukan, yaitu membersihkan data missing value, dan melakukan pengecekan data duplikat.

# Membuat Salinan Data rating
"""

# Membaca dataset untuk dilakukan encoding

df = rating.copy()
df.head()

"""# Menghapus Kolom yang Tidak Diperlukan

Data yang diperlukan hanya ada pada kolom Place_Id, Place_Name, dan Category, jadi hapus yang lain.
"""

place = place.drop(['Description', 'City', 'Time_Minutes', 'Coordinate', 'Lat', 'Long'], axis=1)

"""# Mengecek Missing Value"""

place.isnull().sum()

rating.isnull().sum()

"""# Mengecek Data Duplikat"""

print(f'Jumlah data places yang duplikat: {place.duplicated().sum()}')
print(f'Jumlah data rating yang duplikat: {rating.duplicated().sum()}')

#Menghapus data duplikat
rating.drop_duplicates(inplace = True)

"""# Melakukan Encoding"""

def dict_encoder(col, data=df):

  # Mengubah kolom suatu dataframe menjadi list tanpa nilai yang sama
  unique_val = data[col].unique().tolist()

  # Melakukan encoding value kolom suatu dataframe ke angka
  val_to_val_encoded = {x: i for i, x in enumerate(unique_val)}

  # Melakukan proses encoding angka ke value dari kolom suatu dataframe
  val_encoded_to_val = {i: x for i, x in enumerate(unique_val)}
  return val_to_val_encoded, val_encoded_to_val

"""# Encoding dan Mapping Kolom User"""

# Encoding User_Id
user_to_user_encoded, user_encoded_to_user = dict_encoder('User_Id')

# Mapping User_Id ke dataframe
df['user'] = df['User_Id'].map(user_to_user_encoded)

"""# Encoding dan Mapping Kolom Place"""

# Encoding Place_Id
place_to_place_encoded, place_encoded_to_place = dict_encoder('Place_Id')

# Mapping Place_Id ke dataframe place
df['place'] = df['Place_Id'].map(place_to_place_encoded)

"""# Melihat Gambaran Data untuk Pemodelan"""

# Mendapatkan jumlah user dan place
num_users, num_place = len(user_to_user_encoded), len(place_to_place_encoded)

# Mengubah rating menjadi nilai float
df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)

# Mendapatkan nilai minimum dan maksimum rating
min_rating, max_rating = min(df['Place_Ratings']), max(df['Place_Ratings'])

print(f'Number of User: {num_users}, Number of Place: {num_place}, Min Rating: {min_rating}, Max Rating: {max_rating}')

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df.head()

"""# Modeling and Result

Tahap pengembangan modeling sistem rekomendasi dilakukan untuk membangun model sistem rekomendasi yang dapat menyarankan destinasi wisata terbaik bagi pengguna tertentu berdasarkan rating atau penilaian mereka terhadap destinasi wisata. Teknik yang digunakan untuk membangun model ini adalah content-based filtering recommendation dan collaborative filtering recommendation.

# Model Development dengan Content-based

# TF-IDF Vectorizer
TF-IDF Vectorizer digunakan untuk menemukan representasi fitur yang penting dari setiap kategori destinasi wisata. Alat ini dari library scikit-learn akan mengubah nilai-nilai tersebut menjadi vektor dengan menggunakan metode fit_transform dan transform, serta melakukan pemecahan data menjadi bagian-bagian yang lebih kecil secara langsung.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()

tf.fit(place['Category'])

tf.get_feature_names_out()

"""Mengubah data tempat pada kolom category menjadi bentuk vektor matriks"""

tfidf_matrix = tf.fit_transform(place['Category'])
tfidf_matrix.shape

"""Mengubah bentuk vectorizer yaitu vektor menjadi bentuk matriks."""

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=place.Place_Name
).sample(10, axis=0)

"""# Cosine Similarity
Melakukan perhitungan derajat kesamaan atau similatiry degree antar nama tempat wisata dengan teknik cosine similarity menggunakan library scikit-learn.
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""
Mengubah matriks cosine similarity menjadi bentuk dataframe antar nama tempat (destinasi wisata)."""

cosine_sim_df = pd.DataFrame(
    cosine_sim, index=place.Place_Name, columns=place.Place_Name)
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(10, axis=0)

"""# Recommendation Testing
Melakukan pendefinisian fungsi place_recommendations untuk menampilkan hasil rekomendasi tempat berdasarkan kesamaan kategori dari sebuah tempat.
"""

def place_recommendations(place_name, similarity_data=cosine_sim_df, items=place[['Place_Name', 'Category']], k=5):
    index = similarity_data.loc[:,place_name].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(place_name, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

place_name = 'Tugu Muda Semarang'
place[place.Place_Name.eq(place_name)]

place_recommendations(place_name)

"""Berdasarkan hasil rekomendasi di atas, dapat dilihat bahwa sistem yang dibuat berhasil memberikan rekomendasi tempat berdasarkan sebuah tempat, yaitu 'Tugu Muda Semarang' dan dihasilkan rekomendasi tempat dengan kategori yang sama, yaitu budaya.

# Model Development dengan Collaborative Filtering

Collaborative Filtering adalah teknik merekomendasikan item yang mirip dengan preferensi pengguna yang sama di masa lalu, misalnya berdasarkan penilaian tempat yang telah diberikan oleh seorang pengguna. Sistem akan merekomendasikan tempat berdasarkan riwayat penilaian pengguna tersebut terhadap tempat dan kategorinya.

# Data Preparation
"""

import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

user_ids = rating['User_Id'].unique().tolist()
print('list User_Id: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded User_Id : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke User_Id: ', user_encoded_to_user)

#Proses encoding fitur Place_Id pada dataset ratings menjadi array.
place_ids = rating['Place_Id'].unique().tolist()
place_to_place_encoded = {x: i for i, x in enumerate(place_ids)}
place_encoded_to_place = {i: x for i, x in enumerate(place_ids)}

#Melakukan mapping atau pemetaan kolom user dan place ke dataset ratings yang berkaitan.
rating['user'] = rating['User_Id'].map(user_to_user_encoded)
rating['place'] = rating['Place_Id'].map(place_to_place_encoded)

#Melakukan pengecekan jumlah user, jumlah tempat, penilaian minimal, dan penilaian maksimal.
users_count = len(user_to_user_encoded)
place_count = len(place_encoded_to_place)

rating['rating'] = rating['Place_Ratings'].values.astype(np.float32)

min_rating = min(rating['rating'])
max_rating = max(rating['rating'])

print(f'Users Count: {users_count}')
print(f'Places Count: {place_count}')
print(f'Min rating: {min_rating}')
print(f'Max rating: {max_rating}')

"""# Pembagian data train dan test"""

# Membuat variabel x untuk mencocokkan data user dan place menjadi satu value
x = rating[['user', 'place']].values

# Membuat variabel y untuk membuat rating dari hasil
y = rating['rating'].apply(lambda x: (
    x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
print(x,y)

"""# Model Development
Melakukan pendefinisian kelas RecommenderNet untuk membangun model klasifikasi teks tersebut. Model ini akan memberikan rekomendasi kepada pengguna berdasarkan preferensi atau kecenderungan pengguna di masa lalu. Model ini dapat digunakan dalam berbagai bidang, seperti rekomendasi film, musik, produk, dan lain-lain. RecommenderNet menggunakan algoritma pembelajaran mesin seperti collaborative filtering atau content-based filtering untuk menentukan rekomendasi yang tepat untuk pengguna.

Parameter yang digunakan dalam model ini adalah:

1. **users_count**: jumlah user yang akan jadi input dimension pada user embedding, tepatnya sebagai jumlah elemen dari vocabulary atau kata-kata yang digunakan dalam input data
2. **place_count**: jumlah tempat yang akan jadi input dimension pada tempat embedding, tepatnya sebagai jumlah elemen dari vocabulary atau kata-kata yang digunakan dalam input data
3. **embedding_size**: ukuran embedding akan jadi output dimension pada user embedding dan tempat embedding, yaitu jumlah fitur yang dihasilkan oleh Embedding layer, yang merupakan hasil pengurangan dimensi dari input data.


Embedding layer ini akan mengubah representasi numerik dari input data menjadi representasi vektor yang lebih bermakna dan dapat dipahami oleh model machine learning.
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_places, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_places = num_places
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.places_embedding = layers.Embedding( # layer embeddings places
        num_places,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.places_bias = layers.Embedding(num_places, 1) # layer embedding places bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    places_vector = self.places_embedding(inputs[:, 1]) # memanggil layer embedding 3
    places_bias = self.places_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_places = tf.tensordot(user_vector, places_vector, 2)

    x = dot_user_places + user_bias + places_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Proses kompilasi atau compile dengan:

1. **binary crossentropy loss function**: loss function untuk menghitung loss pada model klasifikasi biner.
2. **adam optimizer**: algoritma optimisasi yang digunakan untuk mengupdate bobot pada model machine learning secara efisien.
3. **metrik RMSE (Root Mean Square Error)**: metrik yang digunakan untuk mengukur seberapa jauh hasil prediksi dari model dari nilai aktual. RMSE dihitung dengan mencari rata-rata dari kuadrat error yang diakumulasikan dari seluruh data.
"""

model = RecommenderNet(num_users, num_place, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.0001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

from keras.callbacks import  EarlyStopping

callbacks = EarlyStopping(
    min_delta=0.0001,
    patience=5,
    restore_best_weights=True,
)

# Melatih model.

history = model.fit(
    x = x_train,
    y = y_train,
    epochs = 100,
    validation_data = (x_val, y_val),
    callbacks = [callbacks]
)

"""Visualisasi grafik data training dan testing untuk masing-masing metrik Root Mean Square Error dan loss function."""

# Menampilkan plot loss dan validation
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.ylim(ymin=0, ymax=0.4)
plt.legend(['train', 'test'], loc='center left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""# Tes Rekomendasi
Melakukan uji coba atau tes rekomendasi tempat yang diberikan. Namun perlu dikertahui terlebih dahulu untuk variabel khusus orang yang belum pernah mengunjungi tempat tersebut (belum memberikan rating) dengan place_not_rated.
"""

place_df = place
rating_df = rating

# Mengambil sample user
user_id = df.User_Id.sample(1).iloc[0]
place_visited_by_user = df[df.User_Id == user_id]

place_df

# Membuat data lokasi yang belum dikunjungi user
place_not_visited = place_df[~place_df['id'].isin(place_visited_by_user.Place_Id.values)]['id']
place_not_visited = list(
    set(place_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)

place_not_visited = [[place_to_place_encoded.get(x)] for x in place_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_place_array = np.hstack(
    ([[user_encoder]] * len(place_not_visited), place_not_visited)
)

"""
Melakukan pengujian prediksi hasil rekomendasi tempat berdasarkan nama tempat dan kategori."""

# Mengambil top 10 recommendation
ratings = model.predict(user_place_array).flatten()
top_ratings_indices = ratings.argsort()[-10:][::-1]  # Ambil 10 rekomendasi tertinggi
recommended_place_ids = [
    place_encoded_to_place.get(place_not_visited[x][0]) for x in top_ratings_indices
]

# Informasi User
print('Daftar rekomendasi untuk: {}'.format('User ' + str(user_id)))
print('===' * 15, '\n')

# Tempat dengan rating wisata paling tinggi dari user
print('----' * 15)
print('Tempat dengan rating wisata paling tinggi dari user')
print('----' * 15)

top_place_user = (
    place_visited_by_user.sort_values(
        by='Place_Ratings',
        ascending=False
    )
    .head(5)
    .Place_Id.values
)

# Tampilkan destinasi yang pernah dikunjungi user dengan rating tertinggi
place_df_rows = place_df[place_df['id'].isin(top_place_user)]
for row in place_df_rows.itertuples():
    print(row.place_name + ':', row.category)

print('')
print('----' * 15)
print('Top 10 place recommendation')
print('----' * 15)

# Tampilkan 10 rekomendasi wisata terbaik
recommended_place = place_df[place_df['id'].isin(recommended_place_ids)]
for row, i in zip(recommended_place.itertuples(), range(1, 11)):  # Ambil 10 tempat
    print(
        f"{i}. {row.place_name}\n    {row.category} Harga Tiket Masuk: {row.price}, Rating Wisata: {row.rating}\n"
    )

print('===' * 15)

"""Berdasarkan hasil rekomendasi tempat di atas, dapat dilihat bahwa sistem rekomendasi mengambil pengguna acak (208), lalu dilakukan pencarian tempat dengan rating terbaik dari user tersebut.

* Water Blaster Bukit Candi Golf: **Taman Hiburan**
* La Kana Chapel: **Taman Hiburan**
* Masjid Agung Ungaran: **Tempat Ibadah**
* Air Terjun Semirang: **Cagar Alam**

Selanjutnya, sistem akan menampilkan 10 daftar tempat yang direkomendasikan berdasarkan kategori yang dimiliki terhadap data pengguna acak tadi. Dapat dilihat bahwa sistem merekomendasikan beberapa tempat dengan kategori yang sama, seperti

1. **Candi Gedong Songo** : Budaya
      
      Harga Tiket Masuk: 10000
      
      Rating Wisata: 4.5

2. **Grand Maerakaca** : Taman Hiburan
   
   Harga Tiket Masuk: 15000

   Rating Wisata: 4.4

3. **Desa Wisata Lembah Kalipancur** : Taman Hiburan
  
  Harga Tiket Masuk: 0
    
  Rating Wisata: 3.9

4. **Hutan Wisata Tinjomoyo Semarang** : Cagar Alam
  
  Harga Tiket Masuk: 3000
  
  Rating Wisata: 4.3

5. **Indonesia Kaya Park** : Taman Hiburan

  Harga Tiket Masuk: 0
  
  Rating Wisata: 4.6

6. **Pantai Cipta** : Bahari

  Harga Tiket Masuk: 5000
  
  Rating Wisata: 4.0

7. **Old City 3D Trick Art Museum** : Budaya

  Harga Tiket Masuk: 50000
  
  Rating Wisata: 4.4

8. **Taman Srigunting** : Taman Hiburan

  Harga Tiket Masuk: 0
  
  Rating Wisata: 4.7

9. **Wisata Alam Wana Wisata Penggaron** : Cagar Alam

  Harga Tiket Masuk: 10000
  
  Rating Wisata: 4.1

10. **Masjid Kapal Semarang** : Tempat Ibadah

  Harga Tiket Masuk: 0
    
  Rating Wisata: 4.1

# Kesimpulan

Dengan begitu, dapat disimpulkan bahwa sistem berhasil melakukan rekomendasi baik dengan pendekatan content-based filtering maupun collaborative filtering. Collaborative filtering membutuhkan data penilaian tempat dari pengguna,

sedangkan pada content-based filtering, data rating tidak dibutuhkan karena sistem akan merekomendasikan berdasarkan konten tempat tersebut, yaitu kategori.
"""